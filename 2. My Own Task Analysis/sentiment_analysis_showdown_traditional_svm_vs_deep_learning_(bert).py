# -*- coding: utf-8 -*-
"""Sentiment Analysis Showdown: Traditional SVM vs. Deep Learning (BERT).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MP4cUpXmNpx4DWKM5NYy9lLNlhaGpsb1

# **Step 00: Import necessary libraries**
"""

import numpy as np
import pandas as pd

"""# **Step 01: Load dataset**"""

df = pd.read_csv("/content/Reviews.csv")
df

from google.colab import drive
drive.mount('/content/drive')

"""# **Step 02: Check last 20 rows**

"""

df.tail(20)

"""# **Step 03: Check data types**"""

df.dtypes

"""# **Step 04: Basic statistical description**"""

df.describe()

"""# **Step 05: Full statistical description**"""

df.describe(include="all")

"""# **Step 06: Dataset info**"""

df.info()

"""# **Step 07: Check for null values**

"""

df.isnull().sum()

"""# **Step 08: Detailed missing data analysis**"""

missing_data = df.isnull()
for column in missing_data.columns.values.tolist():
    print(column)
    print (missing_data[column].value_counts())
    print("")

"""# **Step 09: Import visualization libraries**"""

import matplotlib.pyplot as plt
import seaborn as sns

"""# **Step 10: Sample the dataset**"""

# Step 1: Load the dataset
# df = pd.read_csv('/content/Reviews.csv')
df = df.sample(n=10000, random_state=42)

"""# **Step 11: Calculate mean, median, mode for numerical columns**"""

# Step 2: Calculate Mean, Median, and Mode
# Numerical columns
numerical_cols = ['Score', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time']
print("\nMean, Median, Mode for Numerical Columns:")
for col in numerical_cols:
    mean_val = df[col].mean()
    median_val = df[col].median()
    mode_val = df[col].mode()[0]
    print(f"{col}: Mean = {mean_val:.2f}, Median = {median_val:.2f}, Mode = {mode_val}")

"""# **Step 12: Mode for text columns**"""

# Categorical/text columns
text_cols = ['ProfileName', 'Summary']
print("\nMode for Text Columns:")
for col in text_cols:
    mode_val = df[col].mode()[0]
    print(f"{col}: Mode = {mode_val}")

"""# **Step 13: Handle missing values - numerical columns**"""

# Step 3: Handle Missing Values
# 3.1: Binning for numerical columns (if there were missing values)
# Note: No missing values in numerical columns, but we'll demonstrate the technique
for col in numerical_cols:
    if df[col].isnull().sum() > 0:
        # Create bins based on quantiles
        df[f'{col}_bin'] = pd.qcut(df[col], q=4, duplicates='drop', labels=False)
        # Replace missing values with the mean of the respective bin
        df[col] = df.groupby(f'{col}_bin')[col].transform(lambda x: x.fillna(x.mean()))
        df.drop(columns=[f'{col}_bin'], inplace=True)

"""# **Step 14: Impute missing ProfileName with mode**"""

# 3.2: Impute missing values in ProfileName and Summary
# ProfileName: Replace with mode
profile_mode = df['ProfileName'].mode()[0]
df['ProfileName'] = df['ProfileName'].fillna(profile_mode)

"""# **Step 15: Print ProfileName mode**"""

# Calculate and print the mode of ProfileName
profile_mode = df['ProfileName'].mode()[0]
print(f"Mode of ProfileName: {profile_mode}")

"""# **Step 16: ProfileName frequency count**"""

# Count the frequency of each unique value in the ProfileName column
profile_counts = df['ProfileName'].value_counts()

# Display the results
print("Frequency of each ProfileName:")
print(profile_counts)

"""# **Step 17: Impute missing Summary with mode**"""

# Summary: Replace with mode (or empty string if preferred)
summary_mode = df['Summary'].mode()[0]
df['Summary'] = df['Summary'].fillna(summary_mode)

"""# **Step 18: Print Summary mode**"""

summary_mode = df['Summary'].mode()[0]
print(f"Mode of Summary: {summary_mode}")

"""# **Step 19: Summary frequency count**"""

# Count the frequency of each unique value in the ProfileName column
Summary_counts = df['Summary'].value_counts()

# Display the results
print("Frequency of each Summary:")
print(Summary_counts)

"""#No Missing or NUll Values Now

# **Step 20: Verify no missing values**
"""

# Verify missing values after imputation
print("\nMissing Values After Imputation:")
print(df.isnull().sum())

"""# **Step 21: Install required libraries**"""

# Install required libraries
!pip install pandas numpy matplotlib seaborn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""# **Step 22: Load and analyze dataset**"""

import csv

# Step 1: Load and sample the dataset
# Load dataset from /content/ with robust parsing
dataset_path = '/content/Reviews.csv'
df = pd.read_csv(
    dataset_path,
    quoting=csv.QUOTE_ALL,
    engine='python',
    on_bad_lines='skip',
    encoding='utf-8'
)
print("Dataset loaded successfully. Shape:", df.shape)
print(df.head())
df = df.sample(n=10000, random_state=42)

# Step 2: Define numerical columns
numerical_cols = ['Score', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time']

# Step 3: Summary statistics to understand distribution
print("Summary Statistics:")
print(df[numerical_cols].describe())

# Step 4: Visualize distributions with histograms
plt.figure(figsize=(12, 8))
for i, col in enumerate(numerical_cols, 1):
    plt.subplot(2, 2, i)
    sns.histplot(df[col], bins=20, kde=True)
    plt.title(f'Distribution of {col}')
plt.tight_layout()
plt.show()

# Step 5: Identify outliers with adjusted IQR (multiplier = 3)
outliers_dict = {}
for col in numerical_cols:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 3 * IQR  # Increased multiplier to 3
    upper_bound = Q3 + 3 * IQR  # Increased multiplier to 3

    # Identify outliers
    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col]
    outliers_dict[col] = outliers.tolist()

    # Print column name and outlier values
    print(f"\nOutliers in {col} (IQR multiplier = 3):")
    if len(outliers) > 0:
        print(f"Number of outliers: {len(outliers)}")
        print(f"Outlier values: {outliers.tolist()}")
    else:
        print("No outliers found.")

# Step 6: Visualize outliers with boxplots
plt.figure(figsize=(12, 8))
for i, col in enumerate(numerical_cols, 1):
    plt.subplot(2, 2, i)
    sns.boxplot(x=df[col])
    plt.title(f'Boxplot of {col}')
plt.tight_layout()
plt.show()

"""# **Step 23: Visualize distributions after outlier replacement**"""

# 4.3: Visualize after outlier replacement
plt.figure(figsize=(12, 8))
for i, col in enumerate(numerical_cols, 1):
    plt.subplot(2, 2, i)
    sns.boxplot(x=df[col])
    plt.title(f'Boxplot of {col} After Outlier Replacement')
plt.tight_layout()
plt.show()

"""# **Step 24: Additional data cleaning**"""

# Step 5: Other Necessary Data Cleaning
# 5.1: Remove duplicates
df = df.drop_duplicates()
print(f"\nNumber of rows after removing duplicates: {len(df)}")

# 5.2: Standardize text columns
df['ProfileName'] = df['ProfileName'].str.lower().str.strip()
df['Summary'] = df['Summary'].str.lower().str.strip()
df['Text'] = df['Text'].str.lower().str.strip()

# 5.3: Ensure correct data types
df['Id'] = df['Id'].astype(int)
df['HelpfulnessNumerator'] = df['HelpfulnessNumerator'].astype(int)
df['HelpfulnessDenominator'] = df['HelpfulnessDenominator'].astype(int)
df['Score'] = df['Score'].astype(int)
df['Time'] = df['Time'].astype(int)

"""# **Step 25: Show cleaned dataset**"""

# Step 6: Show the Cleaned Dataset
print("\nCleaned Dataset Info:")
print(df.info())
print("\nFirst 5 rows of Cleaned Dataset:")
print(df.head())

"""# **Step 26: Verify no missing values**"""

# Verify missing values after imputation
print("\nMissing Values After Imputation:")
print(df.isnull().sum())

"""# **Step 27: Handle empty strings in Summary**"""

# Step 4: Check for empty strings or whitespace in Summary and convert to NaN
df['Summary'] = df['Summary'].replace(r'^\s*$', np.nan, regex=True)  # Replace empty or whitespace-only strings with NaN
print("\nMissing Values After Converting Empty Strings to NaN:")
print(df.isnull().sum())

# Step 5: Impute Summary with mode
summary_mode = df['Summary'].mode()[0]
df['Summary'] = df['Summary'].fillna(summary_mode)

# Step 6: Verify missing values after imputation
print("\nMissing Values After Imputation:")
print(df.isnull().sum())

# Step 7: Additional check for empty strings (just to be sure)
empty_summary_count = len(df[df['Summary'].str.strip() == ''])
print(f"\nNumber of empty string values in Summary after imputation: {empty_summary_count}")

"""# **Step 28: Save cleaned dataset**"""

# Optional: Save the cleaned dataset
df.to_csv('/content/Reviews_cleaned.csv', index=False)
print("\nCleaned dataset saved as 'Reviews_cleaned.csv'")

"""# **Step 29: Final null check**"""

df.isnull().sum()

"""# **Step 30: Initialize NLP tools**"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import warnings
warnings.filterwarnings('ignore')

"""# **Step 31: Load cleaned data and prepare for analysis**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import nltk

# Download NLTK data
nltk.download('vader_lexicon')

# Load the cleaned dataset
df = pd.read_csv('/content/Reviews_cleaned.csv')
print("Dataset Loaded Successfully:")
print(df.head())

"""# **Step 32: Text cleaning function**"""

import re
from nltk.corpus import stopwords
nltk.download('stopwords')

# Function to clean text
def clean_text(text):
    text = re.sub(r'[^\w\s]', '', text)  # Remove punctuation
    stop_words = set(stopwords.words('english'))
    text = ' '.join(word for word in text.split() if word.lower() not in stop_words)
    return text

# Apply cleaning to Text column and create Text_Cleaned
df['Text_Cleaned'] = df['Text'].apply(clean_text)
print("\nSample of Text_Cleaned:")
print(df['Text_Cleaned'].head())

"""# **Step 33: Word cloud visualization**"""

# Step 3: Word Cloud
text = ' '.join(df['Text_Cleaned'].dropna())
wordcloud = WordCloud(width=800, height=400, background_color='white', max_words=100).generate(text)
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud of Review Text')
plt.show()

"""# **Step 34: Time-series analysis**"""

# Convert Time to Year
df['Year'] = pd.to_datetime(df['Time'], unit='s').dt.year

# Step 4: Time-Series Plot
reviews_by_year = df.groupby('Year').size()
plt.figure(figsize=(10, 6))
reviews_by_year.plot(kind='line', marker='o')
plt.title('Number of Reviews Over Time')
plt.xlabel('Year')
plt.ylabel('Number of Reviews')
plt.grid(True)
plt.show()

"""# **Step 35: Sentiment analysis with VADER**(Valence Aware Dictionary and sEntiment Reasoner)"""

# Initialize VADER
sid = SentimentIntensityAnalyzer()

# Function to get sentiment
def get_sentiment(text):
    score = sid.polarity_scores(text)['compound']
    return 'positive' if score >= 0.05 else 'negative' if score <= -0.05 else 'neutral'

# Apply sentiment analysis
df['Sentiment'] = df['Text_Cleaned'].apply(get_sentiment)
print("\nSentiment Distribution:")
print(df['Sentiment'].value_counts())

# Visualize sentiment distribution
sns.countplot(x='Sentiment', data=df)
plt.title('Sentiment Distribution of Reviews')
plt.show()

"""# **Step 36: Statistical summary**"""

# Step 7: Statistical Summary
print("\nStatistical Summary of Numerical Columns:")
print(df[['HelpfulnessNumerator', 'HelpfulnessDenominator', 'Score', 'Time']].describe())

"""# **Step 37: TF-IDF and model training**(Term Frequency-Inverse Document Frequency)"""

# TF-IDF Vectorization
tfidf = TfidfVectorizer(max_features=5000)
X = tfidf.fit_transform(df['Text_Cleaned'])
y = df['Sentiment'].map({'positive': 1, 'negative': 0, 'neutral': 2})  # Encode sentiment

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Random Forest Classifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Predict and evaluate
y_pred = rf_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average='weighted')

print(f"\nModel Accuracy: {accuracy:.2f}")
print(f"Model F1 Score: {f1:.2f}")

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""# **Step 38: Save Model and Vectorizer**"""

import joblib

joblib.dump(rf_model, 'rf_sentiment_model.pkl')
joblib.dump(tfidf, 'tfidf_vectorizer.pkl')
print("\nModel and Vectorizer saved successfully.")

"""# **Step 39: Full Pipeline Recap & Initial Evaluation**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report, roc_auc_score, roc_curve
from sklearn.preprocessing import label_binarize
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.corpus import stopwords
import nltk
import re
import joblib

# Download NLTK data
nltk.download('vader_lexicon')
nltk.download('stopwords')

# Load the cleaned dataset
df = pd.read_csv('/content/Reviews_cleaned.csv')
print("Dataset Loaded Successfully:")
print(df.head())

# Step 1: Create Text_Cleaned (if not already present)
def clean_text(text):
    text = re.sub(r'[^\w\s]', '', text)  # Remove punctuation
    stop_words = set(stopwords.words('english'))
    text = ' '.join(word for word in text.split() if word.lower() not in stop_words)
    return text

df['Text_Cleaned'] = df['Text'].apply(clean_text)
print("\nSample of Text_Cleaned:")
print(df['Text_Cleaned'].head())

# Step 2: Sentiment Analysis to Create Sentiment Column
sid = SentimentIntensityAnalyzer()

def get_sentiment(text):
    score = sid.polarity_scores(text)['compound']
    return 'positive' if score >= 0.05 else 'negative' if score <= -0.05 else 'neutral'

df['Sentiment'] = df['Text_Cleaned'].apply(get_sentiment)
print("\nSentiment Distribution:")
print(df['Sentiment'].value_counts())

# Visualize sentiment distribution
sns.countplot(x='Sentiment', data=df)
plt.title('Sentiment Distribution of Reviews')
plt.show()

# Step 3: TF-IDF Vectorization and Model Training
tfidf = TfidfVectorizer(max_features=5000)
X = tfidf.fit_transform(df['Text_Cleaned'])
y = df['Sentiment'].map({'positive': 1, 'negative': 0, 'neutral': 2})

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the Random Forest Classifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Predictions
y_pred = rf_model.predict(X_test)

# Step 4: Model Evaluation
# 4.1: Classification Report
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=['negative', 'positive', 'neutral']))

# 4.2: Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['negative', 'positive', 'neutral'], yticklabels=['negative', 'positive', 'neutral'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# 4.3: Cross-Validation
cv_scores = cross_val_score(rf_model, X, y, cv=5, scoring='accuracy')
print("\nCross-Validation Accuracy Scores:", cv_scores)
print(f"Mean CV Accuracy: {cv_scores.mean():.2f}")
print(f"Standard Deviation: {cv_scores.std():.2f}")

# 4.4: ROC-AUC (One-vs-Rest)
y_test_bin = label_binarize(y_test, classes=[0, 1, 2])
y_pred_prob = rf_model.predict_proba(X_test)

roc_auc = {}
for i, label in enumerate(['negative', 'positive', 'neutral']):
    roc_auc[label] = roc_auc_score(y_test_bin[:, i], y_pred_prob[:, i])
    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_pred_prob[:, i])
    plt.plot(fpr, tpr, label=f'ROC {label} (AUC = {roc_auc[label]:.2f})')

plt.plot([0, 1], [0, 1], 'k--')
plt.title('ROC Curve (One-vs-Rest)')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.show()

print("\nROC-AUC Scores:")
for label, score in roc_auc.items():
    print(f"{label}: {score:.2f}")

# 4.5: Feature Importance
feature_names = tfidf.get_feature_names_out()
importances = rf_model.feature_importances_
top_n = 20
indices = np.argsort(importances)[::-1][:top_n]

plt.figure(figsize=(10, 6))
plt.barh(range(top_n), importances[indices], align='center')
plt.yticks(range(top_n), [feature_names[i] for i in indices])
plt.xlabel('Feature Importance')
plt.title('Top 20 Important Features (Words)')
plt.gca().invert_yaxis()
plt.show()

# 4.6: Error Analysis
error_df = pd.DataFrame({'Text': df.loc[y_test.index, 'Text'], 'Actual': y_test, 'Predicted': y_pred})
error_df['Actual'] = error_df['Actual'].map({0: 'negative', 1: 'positive', 2: 'neutral'})
error_df['Predicted'] = error_df['Predicted'].map({0: 'negative', 1: 'positive', 2: 'neutral'})

misclassified = error_df[error_df['Actual'] != error_df['Predicted']]
print("\nSample of Misclassified Reviews (First 5):")
print(misclassified.head())

misclassified.to_csv('/content/misclassified_reviews.csv', index=False)
print("\nMisclassified reviews saved as 'misclassified_reviews.csv'")

"""#Now try to improve accuracy using different supervised learning algorithms

# **Step 40: Extended Library Imports for Model Comparison**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_auc_score, roc_curve
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.corpus import stopwords
import nltk
import re
import joblib
from sklearn.cluster import KMeans, DBSCAN
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier

"""# **Step 41: Reload Dataset for Model Comparison Phase**"""

# Load the cleaned dataset
df = pd.read_csv('/content/Reviews_cleaned.csv')

"""# **Step 42: Text Cleaning (Re-applied for Safety or Pipeline Reuse)**"""

# Clean text
def clean_text(text):
    text = re.sub(r'[^\w\s]', '', text)
    stop_words = set(stopwords.words('english'))
    text = ' '.join(word for word in text.split() if word.lower() not in stop_words)
    return text

df['Text_Cleaned'] = df['Text'].apply(clean_text)

"""# **Step 43: Sentiment Analysis + TF-IDF + Train-Test Split (Reused Setup)**"""

# Sentiment Analysis
sid = SentimentIntensityAnalyzer()
def get_sentiment(text):
    score = sid.polarity_scores(text)['compound']
    return 'positive' if score >= 0.05 else 'negative' if score <= -0.05 else 'neutral'
df['Sentiment'] = df['Text_Cleaned'].apply(get_sentiment)

# TF-IDF Vectorization
tfidf = TfidfVectorizer(max_features=5000)
X = tfidf.fit_transform(df['Text_Cleaned'])
y = df['Sentiment'].map({'positive': 1, 'negative': 0, 'neutral': 2})

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# **Step 44: Train & Evaluate Multiple Models**"""

# Initialize models
models = {
    'KNN': KNeighborsClassifier(n_neighbors=5),
    'SVM': SVC(kernel='linear', probability=True, random_state=42),
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42)
}

# Evaluate each model
results = {}
for name, model in models.items():
    # Train
    model.fit(X_train, y_train)
    # Predict
    y_pred = model.predict(X_test)
    # Metrics
    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='weighted')
    results[name] = {'Accuracy': accuracy, 'F1 Score': f1}
    print(f"\n{name} Results:")
    print(classification_report(y_test, y_pred, target_names=['negative', 'positive', 'neutral']))
    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['negative', 'positive', 'neutral'], yticklabels=['negative', 'positive', 'neutral'])
    plt.title(f'{name} Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

# Summary of results
print("\nModel Performance Summary:")
for name, metrics in results.items():
    print(f"{name}: Accuracy = {metrics['Accuracy']:.2f}, F1 Score = {metrics['F1 Score']:.2f}")

# Select best model based on F1 Score (more balanced metric for multi-class)
best_model_name = max(results, key=lambda x: results[x]['F1 Score'])
best_model = models[best_model_name]
print(f"\nBest Model: {best_model_name} with F1 Score = {results[best_model_name]['F1 Score']:.2f}")

"""# **Step 45: Clustering using K-Means and DBSCAN**"""

# K-Means Clustering
kmeans = KMeans(n_clusters=3, random_state=42)
kmeans_labels = kmeans.fit_predict(X)
df['KMeans_Cluster'] = kmeans_labels
print("\nK-Means Cluster Distribution:")
print(df.groupby(['KMeans_Cluster', 'Sentiment']).size())

# DBSCAN Clustering
dbscan = DBSCAN(eps=0.5, min_samples=5)
dbscan_labels = dbscan.fit_predict(X.toarray())  # Convert to dense array for DBSCAN
df['DBSCAN_Cluster'] = dbscan_labels
print("\nDBSCAN Cluster Distribution:")
print(df.groupby(['DBSCAN_Cluster', 'Sentiment']).size().head())  # Limited output due to noise (-1)

# Note: Clustering may not align well with sentiment due to high-dimensional TF-IDF space

"""# **Step 46: Predicting sentiment for a new review using the best ML model**"""

# New review
new_review = "This product is absolutely amazing and works perfectly!"
new_review_cleaned = clean_text(new_review)
new_review_tfidf = tfidf.transform([new_review_cleaned])
new_prediction = best_model.predict(new_review_tfidf)
sentiment_map = {0: 'negative', 1: 'positive', 2: 'neutral'}
print(f"\nPrediction for new review: {sentiment_map[new_prediction[0]]}")
print(f"New review text: {new_review}")

# Probability (if available)
if hasattr(best_model, 'predict_proba'):
    new_prob = best_model.predict_proba(new_review_tfidf)
    print(f"Prediction probabilities: {dict(zip(['negative', 'positive', 'neutral'], new_prob[0]))}")

"""# **Step 47: Importing essential libraries and downloading NLTK resources**"""

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from nltk.corpus import stopwords
import re
import joblib
from sklearn.model_selection import train_test_split

# Download NLTK data (if not already downloaded)
try:
    import nltk
    nltk.download('stopwords')
    nltk.download('vader_lexicon')
except:
    pass

"""# **Step 48: Preprocessing reviews, training SVM model, and saving it**"""

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from nltk.corpus import stopwords
import re
import joblib

# Load dataset
df = pd.read_csv('/content/Reviews_cleaned.csv')  # Use Reviews.csv since Reviews_cleaned.csv may not exist

# Create Sentiment column from Score
df['Sentiment'] = df['Score'].apply(lambda x: 'positive' if x >= 4 else 'negative' if x <= 2 else 'neutral')

# Clean text function
def clean_text(text):
    # Handle non-string inputs (e.g., if Text is missing or not a string)
    if not isinstance(text, str):
        text = str(text)
    text = re.sub(r'[^\w\s]', '', text)
    stop_words = set(stopwords.words('english')) - {'not'}
    text = ' '.join(word for word in text.split() if word.lower() not in stop_words)
    return text

# Apply text cleaning
df['Text_Cleaned'] = df['Text'].apply(clean_text)

# Initialize and fit the TF-IDF vectorizer
tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))
X = tfidf.fit_transform(df['Text_Cleaned'])  # Fit and transform in one step
y = df['Sentiment'].map({'positive': 1, 'negative': 0, 'neutral': 2})

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train SVM model
svm = SVC(kernel='linear', probability=True, random_state=42)
svm.fit(X_train, y_train)

# Save the vectorizer and model for future use
joblib.dump(tfidf, 'tfidf_vectorizer.pkl')
joblib.dump(svm, 'svm_model.pkl')

# Function to predict sentiment
def predict_sentiment(review):
    review_cleaned = clean_text(review)
    review_tfidf = tfidf.transform([review_cleaned])  # Transform the new review
    sentiment_map = {0: 'negative', 1: 'positive', 2: 'neutral'}
    prediction = svm.predict(review_tfidf)
    probs = svm.predict_proba(review_tfidf)[0]
    probs_dict = dict(zip(['negative', 'positive', 'neutral'], probs))
    print(f"\nReview: {review}")
    print(f"SVM Prediction: {sentiment_map[prediction[0]]}")
    print(f"SVM Probabilities: {probs_dict}")

# Test the review
predict_sentiment("The taste is not so good")

"""# **Step 49:  Displaying sentiment distribution**"""

print(df['Sentiment'].value_counts())

"""# **Step 50: Testing the text cleaning function**"""

print(clean_text("The taste is not so good"))  # Should output: "taste not good"

"""# **Step 51: Sentiment prediction using Hugging Faceâ€™s transformer pipeline**"""

from transformers import pipeline
sentiment_analyzer = pipeline("sentiment-analysis")
print(sentiment_analyzer("The taste is not so good"))

"""# **Step 52: Interactive sentiment analysis using Hugging Face pipeline**"""

from transformers import pipeline

# Initialize the sentiment analysis pipeline
sentiment_analyzer = pipeline("sentiment-analysis")

# Function to predict sentiment
def predict_sentiment(review):
    result = sentiment_analyzer(review)
    print(f"\nReview: {review}")
    print(f"Sentiment: {result[0]['label']}")
    print(f"Confidence Score: {result[0]['score']:.4f}")

# Main loop to take user input
while True:
    user_review = input("\nPlease enter a review (or type 'exit' to quit): ")
    if user_review.lower() == 'exit':
        print("Exiting the program. Goodbye!")
        break
    if not user_review.strip():
        print("Please enter a valid review.")
        continue
    predict_sentiment(user_review)

"""# **Step 53: Final pipeline with SVM + BERT comparison, using SMOTE for balancing**"""

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from imblearn.over_sampling import SMOTE
from nltk.corpus import stopwords
import re
import joblib
from transformers import pipeline
import csv

# Initialize BERT-based sentiment analyzer
sentiment_analyzer = pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")

# Load dataset
df = pd.read_csv('/content/Reviews_cleaned.csv')

# Create Sentiment column from Score
df['Sentiment'] = df['Score'].apply(lambda x: 'positive' if x >= 4 else 'negative' if x <= 2 else 'neutral')

# Check sentiment distribution before SMOTE
print("Sentiment Distribution Before SMOTE:")
print(df['Sentiment'].value_counts())

# Clean text function
def clean_text(text):
    if not isinstance(text, str):
        text = str(text)
    text = re.sub(r'[^\w\s]', '', text)
    stop_words = set(stopwords.words('english')) - {'not', 'no', 'never'}
    text = ' '.join(word for word in text.split() if word.lower() not in stop_words)
    return text

# Apply text cleaning
df['Text_Cleaned'] = df['Text'].apply(clean_text)

# Check cleaned text for the review
test_review = "The taste is not so good"
print(f"\nCleaned review: {clean_text(test_review)}")

# Initialize and fit the TF-IDF vectorizer
tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))
X = tfidf.fit_transform(df['Text_Cleaned'])
y = df['Sentiment'].map({'positive': 1, 'negative': 0, 'neutral': 2})

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Apply SMOTE to balance the training set
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)

# Check sentiment distribution after SMOTE
print("\nSentiment Distribution After SMOTE (Training Set):")
print(pd.Series(y_train_balanced).value_counts())

# Train SVM model on balanced data
svm = SVC(kernel='linear', probability=True, random_state=42)
svm.fit(X_train_balanced, y_train_balanced)

# Save the vectorizer and model
joblib.dump(tfidf, 'tfidf_vectorizer.pkl')
joblib.dump(svm, 'svm_model.pkl')

# Evaluate SVM model on test set
y_pred = svm.predict(X_test)
print("\nSVM Model Performance on Test Set:")
print(classification_report(y_test, y_pred, target_names=['negative', 'positive', 'neutral']))

# Function to predict sentiment with SVM
def predict_sentiment_svm(review):
    review_cleaned = clean_text(review)
    review_tfidf = tfidf.transform([review_cleaned])
    sentiment_map = {0: 'negative', 1: 'positive', 2: 'neutral'}
    prediction = svm.predict(review_tfidf)
    probs = svm.predict_proba(review_tfidf)[0]
    probs_dict = dict(zip(['negative', 'positive', 'neutral'], probs))
    print(f"\nSVM Prediction for Review: {review}")
    print(f"SVM Sentiment: {sentiment_map[prediction[0]]}")
    print(f"SVM Probabilities: {probs_dict}")

# Function to predict sentiment with BERT
def predict_sentiment_bert(review):
    result = sentiment_analyzer(review)
    star_rating = int(result[0]['label'].split()[0])
    sentiment = 'positive' if star_rating >= 4 else 'negative' if star_rating <= 2 else 'neutral'
    print(f"\nBERT Prediction for Review: {review}")
    print(f"BERT Sentiment: {sentiment}")
    print(f"BERT Confidence Score: {result[0]['score']:.4f} (Star Rating: {star_rating})")

# Test the review with both models
predict_sentiment_svm(test_review)
predict_sentiment_bert(test_review)

# Main loop for user input
while True:
    user_review = input("\nPlease enter a review (or type 'exit' to quit): ")
    if user_review.lower() == 'exit':
        print("Exiting the program. Goodbye!")
        break
    if not user_review.strip():
        print("Please enter a valid review.")
        continue
    predict_sentiment_svm(user_review)
    predict_sentiment_bert(user_review)

"""# **Step 54: Closing The Project Source Code**"""

# Function to predict sentiment with BERT
def predict_sentiment_bert(review):
    result = sentiment_analyzer(review)
    star_rating = int(result[0]['label'].split()[0])
    sentiment = 'positive' if star_rating >= 4 else 'negative' if star_rating <= 2 else 'neutral'
    print(f"\nSVM Prediction for Review: {review}")
    print(f"SVM Sentiment: {sentiment}")
    print(f"SVM Confidence Score: {result[0]['score']:.4f} (Star Rating: {star_rating})")


# Main loop for user input
while True:
    user_review = input("\nPlease enter a review (or type 'exit' to quit): ")
    if user_review.lower() == 'exit':
        print("Exiting the program. Goodbye!")
        break
    if not user_review.strip():
        print("Please enter a valid review.")
        continue
    predict_sentiment_bert(user_review)
    # predict_sentiment_bert(user_review)